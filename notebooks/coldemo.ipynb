{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72443f26",
   "metadata": {},
   "source": [
    "## Rewards\n",
    "\n",
    "NLI encoder consists of:\n",
    "\n",
    "- Embedder $f_\\theta:\\text{text}\\rightarrow\\mathbb{R}^d$\n",
    "- Classifer $g_\\phi:\\mathbb{R}^d\\rightarrow(a_e, a_n, a_c)$ (logits)\n",
    "- (Or $h(\\mathbf{x})=\\text{softmax}(g(\\mathbf{x}))=(p_e, p_n, p_c)$)\n",
    "\n",
    "Recall softmax: $p_i = e^{a_i} / Z, \\ Z=\\sum_{i'\\neq i} e^{a_{i'}}$.\n",
    "\n",
    "\n",
    "Reward signal needs to be a number, not a tuple.  We can either do E vs. C, or E vs $\\lnot C$ (aka E vs. (N or C)).\n",
    "\n",
    "The log-odds of E vs. C are\n",
    "\n",
    "$$\n",
    "\\log \\frac{p_e}{p_c} = \\log \\frac{e^{a_e}/Z}{e^{a_c}/Z} = \\log \\frac{e^{a_e}}{e^{a_c}} = a_e - a_c\n",
    "$$\n",
    "\n",
    "The log-odds of E vs. $\\lnot C$ are\n",
    "\n",
    "$$\n",
    "\\log \\frac{p_e}{p_n + p_c} = a_e - \\log(e^{a_n}+e^{a_c})\n",
    "$$\n",
    "\n",
    "[ continue here ]\n",
    "\n",
    "Assume encoder is calibrated as\n",
    "\n",
    "$$\n",
    "h(\\mathbf{a})_i = p_i = \\text{Pr}(Y=i|\\mathbf{x}) = \n",
    "\\frac{\\text{Pr}(\\mathbf{x}|Y=i)\\pi_i}{\\sum_{i'}\\text{Pr}(\\mathbf{x}|Y=i')\\pi_{i'}}\n",
    "$$\n",
    "\n",
    "[ continue ]\n",
    "\n",
    "So for each state $s_t$ we have associated log-odds\n",
    "\n",
    "$$\n",
    "\\ell_t = \\ell_0 + \\sum_{t'=1}^t \\ell_{t'}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cb4ad",
   "metadata": {},
   "source": [
    "## Returns\n",
    "\n",
    "Assume we have reward $r_t$ for state $s_t$ \n",
    "\n",
    "$$\n",
    "r_t = \\ell_{t+1} - \\ell_t\n",
    "$$\n",
    "\n",
    "(NOTE: because of our independence assumption this reduces to $\\ell_{t+1}$...)\n",
    "\n",
    "Now define the return at time $t$ for utterance $v$ as\n",
    "\n",
    "$$\n",
    "G_v^{(t)} = \\sum_{t'=t}^{T-1} \\gamma^{t'-t} r^{(t')}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d9974",
   "metadata": {},
   "source": [
    "## Cluster-level\n",
    "\n",
    "The tree consists of nodes $S_j^{(t)}$.  Each node represents: \n",
    "\n",
    "- Action-type $a$.  This is the type of action taken at this node.\n",
    "- Persuader clusters $\\mathcal{U} = \\{U_k\\}$.  ($|\\mathcal{U}| = K$)  Each cluster $U_k$ consists of persuader utterances $u_{k_i}$.\n",
    "- Target clusters $\\mathcal{V} = \\{V_m\\}$. ($|\\mathcal{V}| = M$)  Target utterances $v_{m_i}$.\n",
    "\n",
    "For $\\mathcal{U}$, we use a semantic embedding model.  For $\\mathcal{V}$, a NLI-based embedding model.\n",
    "\n",
    "We also track the following $(K, M)$ matrices\n",
    "\n",
    "- $N_{k\\rightarrow m}$: number of times an utterance in $k$ led to $m$\n",
    "- $W_{k\\rightarrow m} = \\sum_{v\\in V_m} G_v$: total returns from $m$ coming from $k$\n",
    "- $Q_{k\\rightarrow m} = (W/N)_{k\\rightarrow m}$: average return\n",
    "- $\\pi_{k\\rightarrow m} = N_{k\\rightarrow m}/\\sum_{m'} N_{k\\rightarrow m'}$: empirical transition matrix (row stochastic)\n",
    "\n",
    "And the following value functions:\n",
    "\n",
    "- $Q_k = \\mathbb{E}[G|u\\in U_k] = \\sum_m \\pi_{k\\rightarrow m} Q_{k\\rightarrow m}$: expected empirical return for a persuader utterance in $U_k$\n",
    "- $Q_a = \\max_k Q_k$: value function for action $a$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5b5ae",
   "metadata": {},
   "source": [
    "## Clustered Open-loop MCTS (COL-MCTS)\n",
    "\n",
    "### Selection\n",
    "\n",
    "Select to an action $a$ using Upper Confidence Tree criteria:\n",
    "$$\n",
    "a^* = \\text{arg}\\max_a \\left[ Q_a + c_1 P(a|s) \\frac{\\sqrt{N(s)}}{1+N(s,a)} \\right]\n",
    "$$\n",
    "\n",
    "This balances exploitation of known high scoring branches (first term) with exploration of less explored branches (second term).\n",
    "\n",
    "$N(s)$ is visits to parent (where we are), $N(s,a)$ is visits to this action, so if $a$ is less explored, this term goes up.\n",
    "\n",
    "For now, assume $P(a|s) = 1/|A|$.\n",
    "\n",
    "### Expansion\n",
    "\n",
    "Expand an unexplored action from this node, choosing from remaining actions uniformly at random.  We now have a path corresponding to an action sequence $(a_{0:t})$ with $a_t$ the newly expanded node.\n",
    "\n",
    "### Rollout\n",
    "\n",
    "We simulate an entire conversation along this sequence (open-loop), using clusters to further condition persuader utterance type and score target utterances (clustered).\n",
    "\n",
    "Specifically, we iterate through the path, at each step (node):\n",
    "\n",
    "- select a persuader cluster $U_k$ using Upper Confidence Bound:\n",
    "$$\n",
    "k^* = \\text{arg}\\max Q_k + c_2 \\sqrt{\\frac{\\log \\sum N_j}{1+N_k}}\n",
    "$$\n",
    "\n",
    "- generate persuader response.  If $k^*$ is \"none\", we only condition on action type; otherwise we further condition on that persuader response type.\n",
    "\n",
    "- generate target response\n",
    "\n",
    "- add this pair to the node, get its cluster assignments, score, and record $(k,m,r)$\n",
    "\n",
    "At the end we have a list of $\\mathcal{P} = (\\text{node}_t, k_t,m_t,r_t)$ for the expanded path.\n",
    "\n",
    "### Backprop\n",
    "\n",
    "Now we traverse through $\\mathcal{P}$ in reverse, computing\n",
    "\n",
    "```\n",
    "G = 0\n",
    "for node, k, m, r in reversed(path):\n",
    "    G = r + gamma * G\n",
    "    node.update(k, m, G)\n",
    "```\n",
    "\n",
    "where `.update` updates node internal metrics ($N$, $Q$, etc).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scope2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
