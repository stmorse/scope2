{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb684798",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72443f26",
   "metadata": {},
   "source": [
    "## Rewards\n",
    "\n",
    "NLI encoder consists of:\n",
    "\n",
    "- Embedder $f_\\theta:\\text{text}\\rightarrow\\mathbb{R}^d$\n",
    "- Classifer $g_\\phi:\\mathbb{R}^d\\rightarrow(a_e, a_n, a_c)$ (logits)\n",
    "- (Or $h(\\mathbf{x})=\\text{softmax}(g(\\mathbf{x}))=(p_e, p_n, p_c)$)\n",
    "\n",
    "Recall softmax: $p_i = e^{a_i} / Z, \\ Z=\\sum_{i'\\neq i} e^{a_{i'}}$.\n",
    "\n",
    "\n",
    "Reward signal needs to be a number, not a tuple.  We can either do E vs. C, or E vs $\\lnot C$ (aka E vs. (N or C)).\n",
    "\n",
    "The log-odds of E vs. C are\n",
    "\n",
    "$$\n",
    "\\log \\frac{p_e}{p_c} = \\log \\frac{e^{a_e}/Z}{e^{a_c}/Z} = \\log \\frac{e^{a_e}}{e^{a_c}} = a_e - a_c\n",
    "$$\n",
    "\n",
    "The log-odds of E vs. $\\lnot C$ are\n",
    "\n",
    "$$\n",
    "\\log \\frac{p_e}{p_n + p_c} = a_e - \\log(e^{a_n}+e^{a_c})\n",
    "$$\n",
    "\n",
    "[ continue here ]\n",
    "\n",
    "Assume encoder is calibrated as\n",
    "\n",
    "$$\n",
    "h(\\mathbf{a})_i = p_i = \\text{Pr}(Y=i|\\mathbf{x}) = \n",
    "\\frac{\\text{Pr}(\\mathbf{x}|Y=i)\\pi_i}{\\sum_{i'}\\text{Pr}(\\mathbf{x}|Y=i')\\pi_{i'}}\n",
    "$$\n",
    "\n",
    "[ continue ]\n",
    "\n",
    "So for each state $s_t$ we have associated log-odds\n",
    "\n",
    "$$\n",
    "\\ell_t = \\ell_0 + \\sum_{t'=1}^t \\ell_{t'}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cb4ad",
   "metadata": {},
   "source": [
    "## Returns\n",
    "\n",
    "Assume we have reward $r_t$ for state $s_t$ \n",
    "\n",
    "$$\n",
    "r_t = \\ell_{t+1} - \\ell_t\n",
    "$$\n",
    "\n",
    "(NOTE: because of our independence assumption this reduces to $\\ell_{t+1}$...)\n",
    "\n",
    "Now define the return at time $t$ for utterance $v$ as\n",
    "\n",
    "$$\n",
    "G_v^{(t)} = \\sum_{t'=t}^{T-1} \\gamma^{t'-t} r^{(t')}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d9974",
   "metadata": {},
   "source": [
    "## Cluster-level\n",
    "\n",
    "The tree consists of nodes $S_j^{(t)}$.  Each node represents: \n",
    "\n",
    "- Action-type $a$.  This is the type of action taken at this node.\n",
    "- Persuader clusters $\\mathcal{U} = \\{U_k\\}$.  ($|\\mathcal{U}| = K$)  Each cluster $U_k$ consists of persuader utterances $u_{k_i}$.\n",
    "- Target clusters $\\mathcal{V} = \\{V_m\\}$. ($|\\mathcal{V}| = M$)  Target utterances $v_{m_i}$.\n",
    "\n",
    "For $\\mathcal{U}$, we use a semantic embedding model.  For $\\mathcal{V}$, a NLI-based embedding model.\n",
    "\n",
    "We also track the following $(K, M)$ matrices\n",
    "\n",
    "- $N_{k\\rightarrow m}$: number of times an utterance in $k$ led to $m$\n",
    "- $W_{k\\rightarrow m} = \\sum_{v\\in V_m} G_v$: total returns from $m$ coming from $k$\n",
    "- $Q_{k\\rightarrow m} = (W/N)_{k\\rightarrow m}$: average return\n",
    "- $\\pi_{k\\rightarrow m} = N_{k\\rightarrow m}/\\sum_{m'} N_{k\\rightarrow m'}$: empirical transition matrix (row stochastic)\n",
    "\n",
    "And the following value functions:\n",
    "\n",
    "- $Q_k = \\mathbb{E}[G|u\\in U_k] = \\sum_m \\pi_{k\\rightarrow m} Q_{k\\rightarrow m}$: expected empirical return for a persuader utterance in $U_k$\n",
    "- $Q_a = \\max_k Q_k$: value function for action $a$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5b5ae",
   "metadata": {},
   "source": [
    "## Clustered Open-loop MCTS (COL-MCTS)\n",
    "\n",
    "### Selection\n",
    "\n",
    "Select to an action $a$ using Upper Confidence Tree criteria:\n",
    "$$\n",
    "a^* = \\text{arg}\\max_a \\left[ Q_a + c_1 P(a|s) \\frac{\\sqrt{N(s)}}{1+N(s,a)} \\right]\n",
    "$$\n",
    "\n",
    "This balances exploitation of known high scoring branches (first term) with exploration of less explored branches (second term).\n",
    "\n",
    "$N(s)$ is visits to parent (where we are), $N(s,a)$ is visits to this action, so if $a$ is less explored, this term goes up.\n",
    "\n",
    "For now, assume $P(a|s) = 1/|A|$.\n",
    "\n",
    "### Expansion\n",
    "\n",
    "Expand an unexplored action from this node, choosing from remaining actions uniformly at random.  We now have a path corresponding to an action sequence $(a_{0:t})$ with $a_t$ the newly expanded node.\n",
    "\n",
    "### Rollout\n",
    "\n",
    "We simulate an entire conversation along this sequence (open-loop), using clusters to further condition persuader utterance type and score target utterances (clustered).\n",
    "\n",
    "Specifically, we iterate through the path, at each step (node):\n",
    "\n",
    "- select a persuader cluster $U_k$ using Upper Confidence Bound:\n",
    "$$\n",
    "k^* = \\text{arg}\\max Q_k + c_2 \\sqrt{\\frac{\\log \\sum N_j}{1+N_k}}\n",
    "$$\n",
    "\n",
    "- generate persuader response.  If $k^*$ is \"none\", we only condition on action type; otherwise we further condition on that persuader response type.\n",
    "\n",
    "- generate target response\n",
    "\n",
    "- add this pair to the node, get its cluster assignments, score, and record $(k,m,r)$\n",
    "\n",
    "At the end we have a list of $\\mathcal{P} = (\\text{node}_t, k_t,m_t,r_t)$ for the expanded path.\n",
    "\n",
    "### Backprop\n",
    "\n",
    "Now we traverse through $\\mathcal{P}$ in reverse, computing\n",
    "\n",
    "```\n",
    "G = 0\n",
    "for node, k, m, r in reversed(path):\n",
    "    G = r + gamma * G\n",
    "    node.update(k, m, G)\n",
    "```\n",
    "\n",
    "where `.update` updates node internal metrics ($N$, $Q$, etc).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21876f9d",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e66e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# hack so we can import normally from other packages\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "from agent.agent import Agent\n",
    "from agent.llm_client import LLMClient\n",
    "from mcts.mcts_node import ConversationState\n",
    "from mcts.mcts_node import OLNode, ResponseBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6cbaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stmorse/projects/scope2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/stmorse/data/mdp/fender/test/v0_-1.00_v1_1.00/turn_0_root.pkl\", \"rb\") as f:\n",
    "    root = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12fda16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children[0].target_bank.embeddings[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scope2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
